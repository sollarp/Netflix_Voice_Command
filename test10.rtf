{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang2057{\fonttbl{\f0\fnil Consolas;}{\f1\fnil\fcharset0 Calibri;}}
{\colortbl ;\red128\green128\blue128;\red0\green0\blue255;\red98\green151\blue85;\red204\green120\blue50;\red169\green183\blue198;\red106\green135\blue89;\red104\green151\blue187;\red136\green136\blue198;\red178\green0\blue178;\red148\green85\blue141;\red170\green73\blue38;\red255\green198\blue109;\red114\green115\blue122;\red165\green194\blue97;}
{\*\generator Riched20 6.3.9600}\viewkind4\uc1 
\pard\box\brdrdash\brdrw0 \sa200\sl276\slmult1\cf1\f0\fs20\lang9 #!/usr/bin/env python\line\line # Copyright 2017 Google Inc. All Rights Reserved.\line #\line # Licensed under the Apache License, Version 2.0 (the "License");\line # you may not use this file except in compliance with the License.\line # You may obtain a copy of the License at\line #\line #      {{\field{\*\fldinst{HYPERLINK http://www.apache.org/licenses/LICENSE-2.0 }}{\fldrslt{http://www.apache.org/licenses/LICENSE-2.0\ul0\cf0}}}}\f0\fs20\line #\line # Unless required by applicable law or agreed to in writing, software\line # distributed under the License is distributed on an "AS IS" BASIS,\line # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\line # See the License for the specific language governing permissions and\line # limitations under the License.\line\line\cf3\i """Google Cloud Speech API sample application using the streaming API.\line\line NOTE: This module requires the additional dependency `pyaudio`. To install\line using pip:\line\line     pip install pyaudio\line\line Example usage:\line     python transcribe_streaming_mic.py\line """\line\line\cf1\i0 # [START speech_transcribe_streaming_mic]\line\cf4 from \cf5 __future__ \cf4 import \cf5 division\line\line\cf4 import \cf5 re\line\cf4 import \cf5 sys\line\cf4 import \cf5 os\line\line\line\cf4 from \cf5 google.cloud \cf4 import \cf5 speech_v1 \cf4 as \cf5 speech\line\cf4 from \cf5 google.cloud.speech_v1 \cf4 import \cf5 enums\line\cf4 from \cf5 google.cloud.speech_v1 \cf4 import \cf5 types\line\cf4 import \cf5 pyaudio\line\cf4 from \cf5 six.moves \cf4 import \cf5 queue\line os.environ[\cf6 "GOOGLE_APPLICATION_CREDENTIALS"\cf5 ] = \cf6 "speech-recognition-268714-0b5941b3965b.json"\line\line\line\cf1 # Audio recording parameters\line\cf5 RATE = \cf7 16000\line\cf5 CHUNK = \cf8 int\cf5 (RATE / \cf7 10\cf5 )  \cf1 # 100ms\line\line\line\line\cf4 class \cf5 MicrophoneStream(\cf8 object\cf5 ):\line     \cf3\i """Opens a recording stream as a generator yielding the audio chunks."""\line\line     \cf4\i0 def \cf9 __init__\cf5 (\cf10 self\cf4 , \cf5 rate\cf4 , \cf5 chunk):\line         \cf10 self\cf5 ._rate = rate\line         \cf10 self\cf5 ._chunk = chunk\line\line         \cf1 # Create a thread-safe buffer of audio data\line         \cf10 self\cf5 ._buff = queue.Queue()\line         \cf10 self\cf5 .closed = \cf4 True\line\line     def \cf9 __enter__\cf5 (\cf10 self\cf5 ):\line         \cf10 self\cf5 ._audio_interface = pyaudio.PyAudio()\line         \cf10 self\cf5 ._audio_stream = \cf10 self\cf5 ._audio_interface.open(\line             \cf11 format\cf5 =pyaudio.paInt16\cf4 ,\line             \cf1 # The API currently only supports 1-channel (mono) audio\line             # {{\field{\*\fldinst{HYPERLINK https://goo.gl/z757pE }}{\fldrslt{https://goo.gl/z757pE\ul0\cf0}}}}\f0\fs20\line             \cf11 channels\cf5 =\cf7 1\cf4 , \cf11 rate\cf5 =\cf10 self\cf5 ._rate\cf4 ,\line             \cf11 input\cf5 =\cf4 True, \cf11 frames_per_buffer\cf5 =\cf10 self\cf5 ._chunk\cf4 ,\line             \cf1 # Run the audio stream asynchronously to fill the buffer object.\line             # This is necessary so that the input device's buffer doesn't\line             # overflow while the calling thread makes network requests, etc.\line             \cf11 stream_callback\cf5 =\cf10 self\cf5 ._fill_buffer\cf4 ,\line         \cf5 )\line\line         \cf10 self\cf5 .closed = \cf4 False\line\line         return \cf10 self\line\line     \cf4 def \cf9 __exit__\cf5 (\cf10 self\cf4 , \cf5 type\cf4 , \cf5 value\cf4 , \cf5 traceback):\line         \cf10 self\cf5 ._audio_stream.stop_stream()\line         \cf10 self\cf5 ._audio_stream.close()\line         \cf10 self\cf5 .closed = \cf4 True\line         \cf1 # Signal the generator to terminate so that the client's\line         # streaming_recognize method will not block the process termination.\line         \cf10 self\cf5 ._buff.put(\cf4 None\cf5 )\line         \cf10 self\cf5 ._audio_interface.terminate()\line\line     \cf4 def \cf12 _fill_buffer\cf5 (\cf10 self\cf4 , \cf5 in_data\cf4 , \cf13 frame_count\cf4 , \cf13 time_info\cf4 , \cf13 status_flags\cf5 ):\line         \cf3\i """Continuously collect data from the audio stream, into the buffer."""\line         \cf10\i0 self\cf5 ._buff.put(in_data)\line         \cf4 return None, \cf5 pyaudio.paContinue\line\line     \cf4 def \cf12 generator\cf5 (\cf10 self\cf5 ):\line         \cf4 while not \cf10 self\cf5 .closed:\line             \cf1 # Use a blocking get() to ensure there's at least one chunk of\line             # data, and stop iteration if the chunk is None, indicating the\line             # end of the audio stream.\line             \cf5 chunk = \cf10 self\cf5 ._buff.get()\line             \cf4 if \cf5 chunk \cf4 is None\cf5 :\line                 \cf4 return\line             \cf5 data = [chunk]\line\line             \cf1 # Now consume whatever other data's still buffered.\line             \cf4 while True\cf5 :\line                 \cf4 try\cf5 :\line                     chunk = \cf10 self\cf5 ._buff.get(\cf11 block\cf5 =\cf4 False\cf5 )\line                     \cf4 if \cf5 chunk \cf4 is None\cf5 :\line                         \cf4 return\line                     \cf5 data.append(chunk)\line                 \cf4 except \cf5 queue.Empty:\line                     \cf4 break\line\line             yield \cf14 b''\cf5 .join(data)\line\line\line\cf4 def \cf12 main\cf5 ():\line     \cf1 # See {{\field{\*\fldinst{HYPERLINK http://g.co/cloud/speech/docs/languages }}{\fldrslt{http://g.co/cloud/speech/docs/languages\ul0\cf0}}}}\f0\fs20\line     # for a list of supported languages.\line     \cf5 language_code = \cf6 'en-US'  \cf1 # a BCP-47 language tag\line\line     \cf5 client = speech.SpeechClient()\line     config = types.RecognitionConfig(\line         \cf11 encoding\cf5 =enums.RecognitionConfig.AudioEncoding.LINEAR16\cf4 ,\line         \cf11 sample_rate_hertz\cf5 =RATE\cf4 ,\line         \cf11 language_code\cf5 =language_code)\line     streaming_config = types.StreamingRecognitionConfig(\cf11 config\cf5 =config\cf4 , \cf11 interim_results\cf5 =\cf4 True\cf5 )\line     \cf8 print\cf5 (\cf6 "speak1: "\cf5 )\line\line     \cf4 with \cf5 MicrophoneStream(RATE\cf4 , \cf5 CHUNK) \cf4 as \cf5 stream:\line         audio_generator = stream.generator()\line         requests = (types.StreamingRecognizeRequest(\cf11 audio_content\cf5 =content)\line                     \cf4 for \cf5 content \cf4 in \cf5 audio_generator)\line         \cf8 print\cf5 (\cf6 "45"\cf5 )\line         responses = client.streaming_recognize(streaming_config\cf4 , \cf5 requests)\line         num_chars_printed = \cf7 0\line         \cf8 print\cf5 (\cf6 "46"\cf5 )\line\line         \cf4 for \cf5 response \cf4 in \cf5 responses:\line             \cf4 if not \cf5 response.results:\line                 \cf8 print\cf5 (\cf6 "no result"\cf5 )\line                 \cf4 continue\line\line             \cf1 # The `results` list is consecutive. For streaming, we only care about\line             # the first result being considered, since once it's `is_final`, it\line             # moves on to considering the next utterance.\line             \cf5 result = response.results[\cf7 0\cf5 ]\line             \cf4 if not \cf5 result.alternatives:\line                 \cf8 print\cf5 (\cf6 "no alternatives"\cf5 )\line                 \cf4 continue\line\line             \cf1 # Display the transcription of the top alternative.\line             \cf5 transcript = result.alternatives[\cf7 0\cf5 ].transcript\line\line\line\line             \cf1 # Display interim results, but with a carriage return at the end of the\line             # line, so subsequent lines will overwrite them.\line             #\line             # If the previous result was longer than this one, we need to print\line             # some extra spaces to overwrite the previous result\line             \cf5 overwrite_chars = \cf6 ' ' \cf5 * (num_chars_printed - \cf8 len\cf5 (transcript))\line\line             \cf8 print\cf5 (\cf6 "loop 1"\cf5 )\line             \cf4 if not \cf5 result.is_final:\line                 sys.stdout.write(transcript + overwrite_chars + \cf6 '\cf4\\r\cf6 '\cf5 )\line                 sys.stdout.flush()\line\line                 \cf13 num_chars_printed \cf5 = \cf8 len\cf5 (transcript)\line\line             \cf4 if \cf5 result.is_final:\line                 \cf8 print\cf5 (\cf6 "you sad: " \cf5 + transcript + overwrite_chars)\line                 \cf4 return \cf5 transcript + overwrite_chars\line\line                 \cf1 # Exit recognition if any of the transcribed phrases could be\line                 # one of our keywords.\line             #if re.search(r'\\b(exit|quit)\\b', transcript, re.I):\line                # print('Exiting..')\line                 #break\line  \line             \cf5 num_chars_printed = \cf7 0\line\line\line\line\cf4 if \cf5 __name__ == \cf6 '__main__'\cf5 :\line     main()\par

\pard\sa200\sl276\slmult1\cf0\f1\fs22\par
}
 